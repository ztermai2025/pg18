## 检查点
检查点是数据库的重要概念，它是我们掌握备份恢复和流复制技术的前提概念。在本章开始讨论的理论模型中我们可以看到：为了恢复当前值18，如果只有基值6，就需要做七次加法运算。如果把基值后移到19，则只需要做两次加法运算。为了加快对当前值的恢复，需要把基值后移，这就是检查点概念的基本内容，即：检查点的作用是为了减少未来数据库恢复所需要的时间。我们可以参考图3.14来理解检查点：

![](x0287.svg) <!-- 检查点的基本含义 8-->

上图中灰色的矩形代表在内存中的脏页，需要写入到磁盘上。如果我们在A点下达一个命令，让共享池中全部的脏页都写入到磁盘中，这就是检查点操作最主要的工作内容。假设检查点操作可以瞬间完成，那么当本次检查点成功执行后，A点左边的WAL记录就不需要了。这是因为A点之前的WAL记录保存着内存中脏页和磁盘上对应数据块的不同，现在在A点发生的检查点操作瞬间完成后，所有的脏页都没有了，内存中的数据页和磁盘上的数据块里面的内容完全一致，A点左边的这些WAL记录当然也就不需要了，这是非常容易理解的一件事情。所以检查点最大的特点是：在一次检查点成功执行后，该检查点前面的所有的WAL记录对于正在运行的数据库没有用了。不过瞬间把所有的脏页都写入磁盘太理想化了，现实中不存在。实际上，需要把内存中所有的脏页都写回到磁盘中的工作是非常耗时的。举个例子，假设共享池配置为32GB大小，其中10%的数据页是脏页，检查点就需要把3.2G的数据共40多万个数据页(= 32GB/8KB/10)写回到磁盘。这当然需要一定的时间，想象一下把一个3GB的文件从C盘拷贝到D盘需要多长时间你就明白了。所以检查点操作不可能瞬间完成，它必然存在一个起点和终点。图3.15展示了检查点操作的起点和终点的概念。

![](x0115.svg) <!-- 检查点的起点和终点的概念 8-->

假设在A点执行一个检查点，我们立刻记录此时的LSN，作为检查点操作的起点。当检查点操作完成后，再插入一条检查点类型的WAL记录，它的位置可能已经在A点右边很远的地方了，这是因为在脏页落盘的过程中可能又会产生大量的WAL记录。A点是检查点的起点，也是检查点WAL记录本来应该待的“逻辑”位置。检查点WAL记录物理所在的B点则是检查点的终点。检查点的WAL记录里有一个指针，记录了A点的LSN，A点被称为“重做点”(redo point)，这是一个非常重要的概念。当检查点成功完成后，假设数据库突然崩溃了，重新启动后要进行崩溃恢复，那么A点之前的WAL记录是崩溃恢复不需要的，但是A点和B点之间的WAL记录依然是需要的。重做点是数据库崩溃恢复的起点。检查点的LSN不重要，检查点WAL记录里面记录的重做点的LSN才重要。这个请读者务必理解和记住。

### 检查点的执行过程

检查点的具体过程是由检查点进程(checkpointer)来执行的，我们很容易看到这个进程的身影：
```
$ ps -ef | grep postgres | grep checkpointer | grep -v grep
postgres  830  829  0 05:45 ?    00:00:00 postgres: checkpointer
```
图3.16来展示了一次检查点的执行过程，水平实线表示各种对象，包括检查点进程，共享池，WAL缓冲池和各种磁盘文件等等，其含义在左边对应列出。水平虚线分割上下两部分，上部分表示内存，下部分表示磁盘。

![](x0031.svg) <!-- 检查点的执行过程 8-->

由上可知，一个检查点的执行总体上分为五个主要的动作：
- 步骤1是检查点发生的开始，此时检查点进程会首先记录当前的WAL指针的位置，这个位置就是检查点WAL记录的逻辑位置，即重做点。
- 步骤2开始在共享池中寻找脏页，依次把这些脏页写入到数据文件中，即脏页的落盘。
- 步骤3表示脏页落盘的过程。这个过程耗时最长，取决于有多少个脏页要落盘，持续几分钟甚至更长时间都不罕见。
- 步骤4的动作是往WAL文件中插入一条检查点的WAL记录。
- 步骤5是把步骤4中的检查点信息写入到控制文件中，以备将来恢复时读取重做点，作为数据库恢复的起点。

函数CreateCheckPoint()是执行检查点的唯一函数，我们可以参考它的关键源代码来理解上述过程。
```c
/* in src/backend/access/transam/xlog.c */
void CreateCheckPoint(int flags)
{
    ......
    /* Begin filling in the checkpoint WAL record */
    MemSet(&checkPoint, 0, sizeof(checkPoint));
    checkPoint.time = (pg_time_t) time(NULL); /* 记录检查点的开始时间 */
    ......
    curInsert = XLogBytePosToRecPtr(Insert->CurrBytePos);
    ...
    checkPoint.redo = curInsert;   /* 步骤(1) - 把当前WAL的位置LSN记录在redo中 */
    ...
    /* 步骤(2)/(3) - CheckPointGuts函数是写脏页到数据文件中。它的执行时间最长 */
    CheckPointGuts(checkPoint.redo, flags); 
    ...
    XLogBeginInsert(); /* 步骤(4) - 把CheckPoint WAL记录写入WAL文件中 */
    XLogRegisterData((char *) (&checkPoint), sizeof(checkPoint));
    recptr = XLogInsert(RM_XLOG_ID, shutdown ? XLOG_CHECKPOINT_SHUTDOWN : XLOG_CHECKPOINT_ONLINE);

    XLogFlush(recptr);
    ...
    UpdateControlFile();  /* 步骤(5) - 更新控制文件 */
    ...
}
```
上述5个步骤都成功执行后，该检查点才算成功完成的。为了恢复当前数据库，只需要重做点之后的WAL记录。爱思考的读者可能会问一个问题：既然检查点是耗时的操作，就存在执行失败的可能性。如果检查点执行失败了，可能脏页并没有百分百可靠地写入到磁盘上，在这种情况下，我们依然需要重做点之前的WAL记录吧？对于这个问题的解答如下：假设数据库突然因为掉电而崩溃了，在它重新启动的阶段，会从控制文件中获取重做点的，即图中的步骤5往控制文件中写入的重做点。既然你已经拿到了重做点，就证明步骤5已经执行成功了，这意味着步骤2，3和4也执行成功了。即：所有的脏页都被可靠地写回数据文件中了，检查点的WAL记录也可靠地被写入到了WAL文件中了。简而言之，你能拿到一个重做点，就意味着这个重做点对应的检查点的执行过程是百分百成功的。数据库恢复是从某个重做点开始的，也可以笼统地说，数据库恢复是从某个检查点开始的，这种说法的真正意思就是指从该检查点对应的重做点开始恢复。图3.17展示了两种情况，第一种情况是正在执行的检查点还没有执行成功时，系统突然崩溃了，则控制文件中依然记录着前一次成功的检查点操作的信息，所以数据库会从前一次成功的检查点开始恢复，即A点。第二种情况是，本次检查点执行成功后，系统突然崩溃了，则可以从本次的检查点开始恢复，即B点。此种情景下，你也可以从A点开始恢复，但没有必要，因为A点到B点之间的WAL记录对于恢复当前数据库没有用处。

![](x0119.svg) <!-- 不同时间点的崩溃 6-->

每次数据库实例启动时，都需要检查上一次关闭是否“干净”，如果上一次关闭不干净，则需要恢复数据文件，这个过程叫做崩溃恢复(crash recovery)。如果需要做崩溃恢复，则PostgreSQL会查看控制文件里的检查点和重做点的信息，以此重做点作为崩溃恢复的起点，如图3.18所示。后面我们会看到，从控制文件中获得上一次成功的检查点的位置信息并不是唯一的选项，我们还可以把检查点的信息保存在别的地方，譬如一个叫做backup_label的文本文件中，后面我们会看到这个小小的但是非常重要的文本文件的作用。

![](x0034.svg) <!-- 从控制文件中获得重做点作为数据库恢复的起点 6-->

控制文件里面的检查点和重做点的信息可以用pg_controldata进行查看。
```
/* 控制文件里记录了最近一次成功的检查点和它相应的重做点 */
$ pg_controldata | grep checkpoint | grep location
Latest checkpoint location:           0/A0000A0
Latest checkpoint's REDO location:    0/A0000A0
```

在检查点执行过程中，步骤3是最耗时的，下面大致了解一下这个步骤到底做了什么，其源码如下：

```c
/* in src/backend/access/transam/xlog.c */
static void CheckPointGuts(XLogRecPtr checkPointRedo, int flags)
{
    CheckPointRelationMap();
    CheckPointReplicationSlots();
    CheckPointSnapBuild();
    CheckPointLogicalRewriteHeap();
    CheckPointReplicationOrigin();
    TRACE_POSTGRESQL_BUFFER_CHECKPOINT_START(flags);
    CheckpointStats.ckpt_write_t = GetCurrentTimestamp();
    CheckPointCLOG();
    CheckPointCommitTs();
    CheckPointSUBTRANS();
    CheckPointMultiXact();
    CheckPointPredicate();
    CheckPointBuffers(flags); /* <--把共享池中的脏页写到磁盘上 */
    TRACE_POSTGRESQL_BUFFER_CHECKPOINT_SYNC_START();
    CheckpointStats.ckpt_sync_t = GetCurrentTimestamp();
    ProcessSyncRequests();
    CheckpointStats.ckpt_sync_end_t = GetCurrentTimestamp();
    TRACE_POSTGRESQL_BUFFER_CHECKPOINT_DONE();
    CheckPointTwoPhase(checkPointRedo);
}
```
可以看出，这个函数比较粗暴，就是依次把共享内存中的相关数据写入对应的文件中，其中最主要的步骤当然是CheckPointBuffers()，即把共享池中的所有脏页刷盘。它只是简单地调用BufferSync()函数，下面是相关的源代码：
```c
/* in src/backend/storage/buffer/bufmgr.c */
static void BufferSync(int flags)
{
int  num_to_scan;
int  mask = BM_DIRTY; /* 标志位，表明该页是否为脏页 */
    ......
    num_to_scan = 0;  /* 记录被发现的脏页个数 */
    for (buf_id = 0; buf_id < NBuffers; buf_id++) { /* 扫描整个共享池 */
        BufferDesc *bufHdr = GetBufferDescriptor(buf_id);
        buf_state = LockBufHdr(bufHdr);
        if ((buf_state & mask) == mask) { /* 若某页是脏页，则标记该页被列为刷盘的候选对象 */
            CkptSortItem *item;
            buf_state |= BM_CHECKPOINT_NEEDED;
            item = &CkptBufferIds[num_to_scan++]; /* 脏页的个数加一 */
            ......
        }
        ......
    }
    if (num_to_scan == 0) return; /* 如果没有发现脏页，就立刻返回 */
    ......
    num_processed = 0;
    num_written = 0;
    while (!binaryheap_empty(ts_heap)) { /* 开始把上述扫描中发现的脏页写盘 */
        BufferDesc *bufHdr = NULL;
        CkptTsStatus *ts_stat = (CkptTsStatus *)
        DatumGetPointer(binaryheap_first(ts_heap));
        buf_id = CkptBufferIds[ts_stat->index].buf_id;
        bufHdr = GetBufferDescriptor(buf_id);
        num_processed++;
        if (pg_atomic_read_u32(&bufHdr->state) & BM_CHECKPOINT_NEEDED) {
	    /* SyncOneBuffer()函数是把指定的页面写盘的具体执行人 */
            if (SyncOneBuffer(buf_id, false, &wb_context) & BUF_WRITTEN) {
                ......
                num_written++;
            }
        }
        ......
     }
     ......
}
```

当检查点执行完毕后，会在日志里记录相关信息，如下所示，里面清楚地记录了写了7个脏页(wrote 7 buffers)，占比多少等等信息。

```
2023-03-24 05:19:36.572 MDT [4818] LOG:  checkpoint starting: immediate force wait
2023-03-24 05:19:36.577 MDT [4818] LOG:  checkpoint complete: wrote 7 buffers (0.0%); 
0 WAL file(s) added, 0 removed, 0 recycled; write=0.002 s, sync=0.001 s, total=0.005 s; 
sync files=5, longest=0.001 s, average=0.001 s; distance=0 kB, estimate=0 kB
```

重做点是检查点的逻辑位置，只不过因为检查点操作是一个非常耗时的操作，所以它有起点和终点两个不同的位置。重做点就是检查点操作的起点，它的LSN当然小于或者等于该检查点的WAL记录的LSN，我们可以简称为：重做点小于等于检查点。如果重做点小于检查点，则表明在步骤2和3进行时，数据库中依然有活动的事务在修改数据。什么情况下重做点和检查点相等呢？有两种情况。第一种情况是检查点发生时，共享池中没有脏页，函数CheckPointGuts()就立刻返回，导致检查点的WAL记录立即被写入到它的逻辑位置，就是重做点的位置。第二种情况发生在正常关闭数据库时。检查点分为两种类型，在线检查点(onLine checkpoint)和关闭型检查点(shutdown checkpoint)，其相关定义如下：
```
/* in src/include/catalog/pg_control.h */
#define XLOG_CHECKPOINT_SHUTDOWN                0x00
#define XLOG_CHECKPOINT_ONLINE                  0x10
```
顾名思义，在数据库运行过程中发生的普通检查点基本上都是在线类型的。数据库关闭时，关闭流程在最后会写入一个检查点，它的类型被叫做关闭型。因为此时已经不可能有数据被修改的情况发生了，故关闭型的检查点必定等于其重做点。下面我们做一个实验：
```
$ pg_ctl stop /* 干净地关闭数据库 */
waiting for server to shut down.... done
server stopped
$ pg_controldata | grep location | grep checkpoint /* 查看检查点信息 */
Latest checkpoint location:           0/18CB0D8    /* 两者是相等的 */
Latest checkpoint's REDO location:    0/18CB0D8    /* 两者是相等的 */
$ pg_waldump -p $PGDATA/pg_wal -s 0/18CB0D8 -n 1   /* 把这条WAL记录打印出来 */
rmgr: XLOG        len (rec/tot):    114/   114, tx:          0, lsn: 0/018CB0D8, prev 0/018CB0A0,
desc: CHECKPOINT_SHUTDOWN redo 0/18CB0D8; tli 1; prev tli 1; fpw true; xid 0:745; oid 16395; 
multi 1; offset 0; oldest xid 722 in DB 1; oldest multi 1 in DB 1; oldest/newest commit 
timestamp xid: 0/0; oldest running xid 0; shutdown
$
```
我们可以看到，当数据库被干净地关闭以后，其检查点的类型为CHECKPOINT_SHUTDOWN，即关闭型检查点，它的检查点的LSN和重做点的LSN是完全一样的，都是0/18CB0D8。根据这个规律，我们可以判断一个数据库是否是被干净地关闭掉的。因为重做点和检查点本质上是一回事，所以我们在后文中可以把这两个术语交叉使用。

### 检查点的WAL记录

理解了检查点的执行过程后，本节考察一下它的WAL记录的细节。其WAL记录的格式非常简单，和提交型的WAL记录格式差不多，也分为三个部分：记录头，数据，外加中间一个小头，如图3.19所示。

![](x0032.svg) <!-- 检查点WAL记录的结构 -->

上一节已经介绍了XLogRecord和XLogRecordDataHeaderShort的具体结构，下面我们只看一下数据部分的内容，它实际上是一个CheckPoint结构，其具体定义如下：

```c
typedef uint64 XLogRecPtr;
typedef int64 pg_time_t;
/* in src/include/catalog/pg_control.h */
typedef struct CheckPoint {
    XLogRecPtr        redo;             /* RedoPoint */
    TimeLineID        ThisTimeLineID;   /* current TLI */
    TimeLineID        PrevTimeLineID;   /* previous TL */
    bool              fullPageWrites;   /* current full_page_writes */
    FullTransactionId nextXid;          /* next free transaction ID */
    Oid               nextOid;          /* next free OID */
    MultiXactId       nextMulti;        /* next free MultiXactId */
    MultiXactOffset   nextMultiOffset;  /* next free MultiXact offset */
    TransactionId     oldestXid;        /* cluster-wide minimum datfrozenxid */
    Oid               oldestXidDB;      /* database with minimum datfrozenxid */
    MultiXactId       oldestMulti;      /* cluster-wide minimum datminmxid */
    Oid               oldestMultiDB;    /* database with minimum datminmxid */
    pg_time_t         time;             /* time stamp of checkpoint */
    TransactionId     oldestCommitTsXid;
    TransactionId     newestCommitTsXid;
    TransactionId     oldestActiveXid;
} CheckPoint;
```
该结构体比较复杂，根据目前所学的知识，我们只关心三个成员变量：redo，即本检查点的重做点。fullPageWrites表示是否是全页写，后面会介绍其具体含义。time，记录检查点发生的开始时间，可以参考上述CreateCheckPoint()函数。下面的实验演示了如何查看检查点WAL记录的原始内容。
```
postgres=# \! pg_controldata | grep checkpoint | grep location
Latest checkpoint location:           0/3000098
Latest checkpoint's REDO location:    0/3000060
postgres=# checkpoint;     /* 手工执行一个检查点 */
CHECKPOINT
/* 发现检查点和重做点的LSN均向后移动了 */
postgres=# \! pg_controldata | grep checkpoint | grep location
Latest checkpoint location:           0/3000180
Latest checkpoint's REDO location:    0/3000148
postgres=# \! pg_controldata | grep TimeLine  /* 当前的时间线是1 */
Latest checkpoint's TimeLineID:       1
Latest checkpoint's PrevTimeLineID:   1
```
手工执行CHECKPOINT命令后，控制文件里的检查点和重做点的LSN都向后移动了：检查点从0/3000098移动到了0/3000180，重做点从0/3000060移动到了0/3000148。下面使用pg_waldump和pg_walinspect来查看一下该条WAL记录。
```
postgres=# \! pg_waldump -p $PGDATA/pg_wal -n 1 -s 0/3000180
rmgr: XLOG        len (rec/tot):    114/   114, tx:          0, lsn: 0/03000180, prev 0/03000148,
desc: CHECKPOINT_ONLINE redo 0/3000148; tli 1; prev tli 1; fpw true; xid 0:765; oid 24700; 
multi 1; offset 0; oldest xid 716 in DB 1; oldest multi 1 in DB 1; oldest/newest commit 
timestamp xid: 0/0; oldest running xid 765; online
postgres=# SELECT * FROM pg_get_wal_record_info('0/3000180');
-[ RECORD 1 ]----+-------------------------------------------------------------------------
start_lsn        | 0/3000180
end_lsn          | 0/30001F8
prev_lsn         | 0/3000148
xid              | 0
resource_manager | XLOG
record_type      | CHECKPOINT_ONLINE
record_length    | 114
main_data_length | 88
fpi_length       | 0
description      | redo 0/3000148; tli 1; prev tli 1; fpw true; xid 0:765; oid 24700; 
multi 1; offset 0; oldest xid 716 in DB 1; oldest multi 1 in DB 1; oldest/newest 
commit timestamp xid: 0/0; oldest running xid 765; online
block_ref        |
```
对比两个工具的输出结果，可以得到如下分析结果：
- 该WAL记录的总长度是114个字节，真正的记录长度是88个字节，因为tot = 114，main_data_length=88。
- 该WAL记录的前一条WAL记录的LSN是0/03000148，后一条是0/30001F8。
- 该检查点的重做点是0/3000148，因为有"redo 0/3000148"的输出。
- 该检查点是CHECKPOINT_ONLINE类型的。
- 数据库集群处于全页写模式(fpw true)。


如果不甘心，我们还可以使用大杀器hexdump观察其原始的形态，结果如下：
```
postgres=# \! hexdump -C $PGDATA/pg_wal/000000010000000000000003 -s 384 -n 114
00000180  72 00 00 00 00 00 00 00  48 01 00 03 00 00 00 00  |r.......H.......|
00000190  10 00 00 00 DD EC D2 20  FF 58 48 01 00 03 00 00  |....... .XH.....|
000001a0  00 00 01 00 00 00 01 00  00 00 01 00 00 00 00 00  |................|
000001b0  00 00 FD 02 00 00 00 00  00 00 7C 60 00 00 01 00  |..........|`....|
000001c0  00 00 00 00 00 00 CC 02  00 00 01 00 00 00 01 00  |................|
000001d0  00 00 01 00 00 00 00 00  00 00 FB 7C 1E 64 00 00  |...........|.d..|
000001e0  00 00 00 00 00 00 00 00  00 00 FD 02 00 00 00 00  |................|
000001f0  00 00                                             |..|
000001f2
```

仔细对比上述的原始结果和CheckPoint的数据结构，很容易分析出XLogRecord的各成员变量的取值。xl_tot_len的值是114 (0x72)，表明整个WAL记录是114个字节(24 + 2 + 88)。xl_xid的值为0，检查点不属于任何一个事务。xl_prev的值是0/3000148("48 01 00 03 00 00 00 00")，代表本WAL记录前面的WAL记录的LSN。xl_info的值是0x10。RmgrId的值是0，表示类型是RM_XLOG_ID。xl_crc的值是0x20D2ECDD ("DD EC D2 20")，表示校验码。 XLogRecordDataHeaderShort各成员变量的取值为：id的值是0xFF，表示这是一条短类型的记录，参考XLR_BLOCK_ID_DATA_SHORT的定义。data_length的值是0x58，表示其后的CheckPoint结构的总长度，共88个字节。 

CheckPoint各成员变量的取值是：redo的值是0/3000148，这就是本检查点WAL记录对应的重做点。ThisTimeLineID的值为1，表示当前时间线是1。PrevTimeLineID是1，表示前一个时间线也是1。时间线的最小值是1，以后我们再讨论时间线的问题。fullPageWrites的值是1，表示数据库集群的全页写模式处于激活状态。time是8个字节，表示本检查点发生开始的时间戳，里面的内容我们就不需要关心了。

### 检查点的执行时机

前面的实验都是以超级用户的身份手工执行CHECKPOINT命令。当然这种情况非常少见，你总不能搬个小板凳坐在数据库服务器面前，时不时手工执行一条CHECKPOINT命令吧。PostgreSQL设置了一个时间间隔，由checkpoint_timeout参数规定，缺省值为5分钟，即每隔5分钟就会自动触发一次检查点。除此之外，触发检查点的条件还有如下几种情况：
- 每当$PGDATA/pg_wal目录下的WAL文件的总体积超过一定大小时，也会触发一个检查点。这个体积由参数max_wal_size规定，缺省值是1GB，即pg_wal目录下的WAL文件累积到1GB时自动触发检查点，导致全部的WAL文件都可以被安全删除，缓解pg_wal目录中文件体积过大的压力。
- 某一些特定操作，如开始备份，数据库恢复结束后，关闭数据库集群的最后阶段，也会触发检查点。

由于检查点的操作非常耗时，所以有两种选择，一种是开足马力，尽快地把内存中的全部脏页刷到磁盘上，这种模式被称为“立即”模式或者“快速”模式。这种模式会导致系统的I/O激增，数据库的性能下降，影响用户的使用体验。另外一种方式是悠着点来，让检查点在checkpoint_timeout参数规定的时间内慢悠悠地写完。此种模式下，I/O的负荷被均匀地分散在一个比较宽松的时间段内，所以对数据库的性能冲击变小了。参数checkpoint_completion_target规定了两次检查点之间的时间段的百分比，其缺省值是0.9。例如，checkpoint_timeout的值是5分钟，checkpoint_completion_target是0.9，则一次检查点必须在4.5分钟(= 5 * 0.9)内完成。这个参数的含义请参考图3.20。

![](x0037.svg) <!-- 检查点的执行时间 -->

针对把所有的脏页刷盘的全检查点比较耗时的问题，Oracle数据库和华为的OpenGauss数据库中提出了“增量检查点”的概念，这种技术是对全检查点的一种优化，有兴趣的读者可以自行研究这个概念和具体的技术细节。

### 全页写

很显然，为了恢复原始值，必须有基值和增量，两者缺一不可。没有基值，光有增量，也是无根之木，无源之水。但是有些情况下基值可能会丢失，全页写(FPW: full page write)技术就是为了解决数据块损坏的问题而设计的。它的基本思想是：在某次检查点发生之后，若某个数据页是第一次被修改，则对应的WAL记录保存的不是本次的修改信息，而是把整个数据页的数据都写入到WAL记录中，即：在WAL文件中不仅仅记录增量，也记录基值。这样一来，即使真正的数据块损坏了，它的副本在WAL文件中还能找到，这就有效地解决了数据块损坏的问题。参数full_page_writes控制FPW功能的开启和关闭，缺省值是打开状态(on)。普通的WAL记录只有几百个字节，而FPW的WAL记录可能有几K字节。所以，如果FPW开启后检查点发生的很频繁，WAL文件的体积会快速膨胀。对于WAL文件快速膨胀的问题，解决方法就是调整checkpoint_timeout和max_wal_size等参数，让检查点发生的不要那么频繁。譬如我公司生产库的检查点发生时间被控制在30分钟。此外，参数wal_compression可以把FPW类型的WAL记录压缩，在一定程度上缓解了WAL文件体积膨胀的问题。下面的实验展示了FPW的基本内容。
```
/* 检查一下两个参数 */
oracle=# \! cat $PGDATA/postgresql.conf | grep -E 'full_page_writes|wal_compression'
full_page_writes = on                  # recover from partial page writes
wal_compression = off                  # enables compression of full-page writes;
/* 做一些准备工作，准备一张表和两条记录 */
oracle=# CREATE TABLE stateus(id CHAR(2), name VARCHAR(64));
CREATE TABLE
oracle=# INSERT INTO stateus VALUES('TN', 'Tennessee'),('MA', 'Massachusetts');
INSERT 0 2
oracle=# SELECT id, name FROM stateus ORDER BY id;
 id |     name
----+---------------
 MA | Massachusetts
 TN | Tennessee
(2 rows)
oracle=# CHECKPOINT;  /* 手工执行一个检查点，确保后面的插入操作能够触发FPW */
CHECKPOINT
oracle=# SELECT pg_current_wal_lsn();
 pg_current_wal_lsn
--------------------
 0/1A9A5E8
(1 row)
oracle=# INSERT INTO stateus VALUES('WY', 'Wyoming'); /* 再插入一条记录 */
INSERT 0 1
oracle=# SELECT pg_current_wal_lsn();
 pg_current_wal_lsn
--------------------
 0/1A9A728
(1 row)
```
表stateus里面已经有了2条记录，当手工执行一个检查点后，紧接着再往此表中插入一条记录，肯定会产生一条FPW类型的WAL记录。下面是pg_waldump解析出的该条WAL记录的内容。
```
$ pg_waldump -s 0/1A9A5E8 -n 2
rmgr: Heap        len (rec/tot):     54/   218, tx:        762, lsn: 0/01A9A5E8, prev 0/01A9A5B0,
desc: INSERT off 3 flags 0x00, blkref #0: rel 1663/16384/16505 blk 0 FPW   /* <-- FPW表示全页写 */
rmgr: Transaction len (rec/tot):     34/    34, tx:        762, lsn: 0/01A9A6C8, prev 0/01A9A5E8,
desc: COMMIT 2023-03-24 09:31:27.173624 MDT
```
LSN为0/01A9A5E8的WAL记录最后显示了"FPW"的字样，表明这条WAL记录是FPW类型，FPW类型的记录在源代码中被称为“备份块”(backup block)或者“全页镜像”(FPI: full-page image)。你还可以观察到长度信息(rec/tot)分别显示为54和218，其中218表示该记录的总长度，54表示记录头有54个字节，两者的差值就是数据页的全部数据的长度。FPI分为压缩和未压缩两种形式，未压缩的WAL记录的格式可以参考图3.21，其中的数字代表对应的结构的长度，单位是字节。

![](x0139.svg) <!-- 备份块/FPI的基本结构 -->

相关的数据结构的具体定义如下。在此我们不去深究每一个数据结构的具体含义，只要一个整体的概念即可。FPI中包含了一个数据块的全部内容，所以在未来做数据库恢复时，直接拿这些数据对数据块进行全覆盖即可，数据块本身的内容无关紧要，损坏了也没有关系。数据块中的空闲空间是一个“洞”(hole)，在WAL记录中存储时肯定不会存放这部分无效的信息，所以XLogRecordBlockImageHeader有一个成员变量hole_offset记录数据块中空闲空间的偏移量。

```c
/* in src/include/access/xlogrecord.h */
typedef struct XLogRecordBlockHeader {
    uint8   id;           /* block reference ID */
    uint8   fork_flags;   /* fork within the relation, and flags */
    uint16  data_length;  /* number of payload bytes (not including page image) */
} XLogRecordBlockHeader;
typedef struct XLogRecordBlockImageHeader {
    uint16          length;       /* number of page image bytes */
    uint16          hole_offset;  /* number of bytes before "hole" */
    uint8           bimg_info;    /* flag bits, see below */
} XLogRecordBlockImageHeader;
typedef unsigned int Oid;
/* in src/include/storage/relfilenode.h */
typedef struct RelFileNode {
    Oid  spcNode;  /* tablespace */
    Oid  dbNode;   /* database */
    Oid  relNode;  /* relation */
} RelFileNode;
/* in src/include/storage/block.h */
typedef uint32 BlockNumber
/* 具体代码可参考 src/backend/access/transam/xloginsert.c : XLogRecordAssemble() */

```
下面的实验显示了该FPI记录的原始数据。因为LSN是0/01A9A5E8，所以其偏移量为0xA9A6C8，即11118056，原始输出的结果如下：
```
$ hexdump -C 000000010000000000000001 -s 11118056 -n 218
00a9a5e8  DA 00 00 00 FA 02 00 00  B0 A5 A9 01 00 00 00 00  |................|
00a9a5f8  00 0A 00 00 6E A1 96 95  00 10 00 00 A4 00 24 00  |....n.........$.|
00a9a608  03 7F 06 00 00 00 40 00  00 79 40 00 00 00 00 00  |......@..y@.....|
00a9a618  00 FF 03 00 00 00 00 A0  A4 A9 01 00 00 00 00 24  |...............$|
00a9a628  00 80 1F 00 20 04 20 00  00 00 00 D8 9F 4A 00 A8  |.... . ......J..|
00a9a638  9F 52 00 80 9F 46 00 FA  02 00 00 00 00 00 00 00  |.R...F..........|
00a9a648  00 00 00 00 00 00 00 03  00 02 00 02 08 18 00 07  |................|
00a9a658  57 59 11 57 79 6F 6D 69  6E 67 00 00 00 00 00 F9  |WY.Wyoming......|
00a9a668  02 00 00 00 00 00 00 00  00 00 00 00 00 00 00 02  |................|
00a9a678  00 02 00 02 09 18 00 07  4D 41 1D 4D 61 73 73 61  |........MA.Massa|
00a9a688  63 68 75 73 65 74 74 73  00 00 00 00 00 00 00 F9  |chusetts........|
00a9a698  02 00 00 00 00 00 00 00  00 00 00 00 00 00 00 01  |................|
00a9a6a8  00 02 00 02 09 18 00 07  54 4E 15 54 65 6E 6E 65  |........TN.Tenne|
00a9a6b8  73 73 65 65 00 00 00 03  00 00                    |ssee......|
```

只要你足够耐心，对照上面的数据结构，不难从原始输出中找出对应的成员变量的值。虽然我们对数据页保存在FPI中的部分的具体格式不清楚，但从上述输出的右边信息栏中可以看到除了新插入的"Wyoming"，还有"Massachusetts"和"Tennessee"的字符串，单一的插入操作居然保存了整个数据块的三条记录，明显和前一节分析的插入操作的WAL记录不同，由此证明了整个数据页都被保存在FPI中了。所以，即使未来这个数据块损坏了，依然可以通过这条WAL记录完整恢复它。工具pg_waldump有一个选项--save-fullpage，可以把一条FPI类型的WAL记录转化成一个单独的数据页，存放在指定的目录下，具体操作演示如下：
```
$ pg_waldump -s 0/01889348 -n 1 --save-fullpage=/opt/data/fpi 
rmgr: Heap        len (rec/tot):     54/   166, tx:        736, lsn: 0/01889348, prev 0/01889310,
desc: INSERT off: 2, flags: 0x00, blkref #0: rel 1663/24576/24577 blk 0 FPW
$ cd fpi/
$ ls -l  /* 可以看到被转储出来的数据页是8192个字节，它的文件名包含了数据块的编号等信息 */
total 8
-rw-rw-r-- 1 postgres postgres 8192 Dec 28 18:09 00000001-00000000-01889348.1663.24576.24577.0_main
$ hexdump -C 00000001-00000000-01889348.1663.24576.24577.0_main 
00000000  00 00 00 00 98 91 88 01  00 00 00 00 20 00 b0 1f  |............ ...|
00000010  00 20 04 20 00 00 00 00  d8 9f 48 00 b0 9f 42 00  |. . ......H...B.|
00000020  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
*
00001fb0  e0 02 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00001fc0  02 00 02 00 02 08 18 00  07 54 58 0d 54 65 78 61  |.........TX.Texa|
00001fd0  73 00 00 00 00 00 00 00  df 02 00 00 00 00 00 00  |s...............|
00001fe0  00 00 00 00 00 00 00 00  01 00 02 00 02 08 18 00  |................|
00001ff0  07 43 4f 13 43 6f 6c 6f  72 61 64 6f 00 00 00 00  |.CO.Colorado....|
00002000
```

为了减少因为全页写而导致的WAL文件膨胀的问题，我们可以把WAL记录进行压缩。下面的实验展示了打开WAL压缩功能后的情形。

```
postgres=# ALTER SYSTEM SET wal_compression=on;
ALTER SYSTEM
postgres=# SELECT pg_reload_conf();
 pg_reload_conf
----------------
 t
(1 row)
postgres=# SHOW wal_compression; /* WAL压缩功能已经打开，使用pglz压缩算法 */
 wal_compression
-----------------
 pglz
(1 row)
oracle=# CHECKPOINT;  /* 再执行一个检查点 */
CHECKPOINT
oracle=# SELECT pg_current_wal_lsn();
 pg_current_wal_lsn
--------------------
 0/1A9B048
(1 row)
oracle=# INSERT INTO stateus VALUES('MD', 'MaryLand'); /* 插入新记录 */
INSERT 0 1
oracle=# \! pg_waldump -s 0/1A9B048 -n 3  /* 看看里面的结果 */
rmgr: Standby     len (rec/tot):     50/    50, tx:          0, lsn: 0/01A9B048, ......
rmgr: Heap        len (rec/tot):     56/   197, tx:        763, lsn: 0/01A9B080, prev 0/01A9B048,
desc: INSERT off 4 flags 0x00, blkref #0: rel 1663/16384/16505 blk 0 FPW 
rmgr: Transaction len (rec/tot):     34/    34, tx:        763, lsn: 0/01A9B148, prev 0/01A9B080,
desc: COMMIT 2023-03-24 09:49:10.427555 MDT
/* 使用hexdump大杀器 */
oracle=# \! hexdump -C $PGDATA/pg_wal/000000010000000000000001 -s 11120768 -n 197
00a9b080  C5 00 00 00 FB 02 00 00  48 B0 A9 01 00 00 00 00  |........H.......|
00a9b090  00 0A 00 00 A1 36 25 7A  00 10 00 00 8D 00 28 00  |.....6%z......(.|
00a9b0a0  07 30 1F 7F 06 00 00 00  40 00 00 79 40 00 00 00  |.0......@..y@...|
00a9b0b0  00 00 00 FF 03 00 00 00  00 00 C8 A6 A9 01 01 01  |................|
00a9b0c0  08 28 00 58 1F 00 20 04  02 20 01 0C D8 9F 4A 00  |.(.X.. .. ....J.|
00a9b0d0  A8 9F 00 52 00 80 9F 46  00 58 9F 30 48 00 FB 02  |...R...F.X.0H...|
00a9b0e0  01 16 07 01 04 00 00 02  00 02 08 18 00 07 4D 00  |..............M.|
00a9b0f0  44 13 4D 61 72 79 4C 61  54 6E 64 01 18 FA 0C 28  |D.MaryLaTnd....(|
00a9b100  03 05 28 57 00 59 11 57  79 6F 6D 69 6E AA 67 02  |..(W.Y.Wyomin.g.|
00a9b110  18 F9 0C 28 02 01 02 09  01 50 00 41 1D 4D 61 73  |...(.....P.A.Mas|
00a9b120  73 61 63 80 68 75 73 65  74 74 73 04 20 05 0D 30  |sac.husetts. ..0|
00a9b130  01 05 30 54 4E 15 54 65  80 6E 6E 65 73 73 65 65  |..0TN.Te.nnessee|
00a9b140  00 19 04 00 00                                    |.....|
```

上面的输出很清晰地显示：只有3条记录的FPI总长度是218个字节，而有4条记录的FPI的总长度只有197个字节，压缩的效果显现出来了，而且里面的内容已经相对不可读了。

Oracle数据库拥有自己独立的文件系统ASM，PostgreSQL却要依赖操作系统的文件系统提供的基本磁盘读写功能，但文件系统并不能总让PostgreSQL满意，这导致PostgreSQL不得不做一些可靠性设计，FPW就是一种可靠性设计。建议用户打开该功能，所以它的缺省值被设置为on。

### PostgreSQL的写磁盘操作

设计WAL记录的目的是为了保护数据文件中的数据块，所以WAL记录被可靠地写入掉电不丢失数据的磁盘上，是数据不丢失的根本保证。PostgreSQL本身并没有控制磁盘读写的功能，它要依赖操作系统的文件系统来完成最终的磁盘读写工作，在Linux平台上就是使用open/read/write/close等系统调用，在Windows平台上使用WriteFile()系统调用。下面是一个简单的磁盘文件写操作的例子：
```
$ cat writefile.c /* 显示源代码的内容 */
#include <fcntl.h>
#include <unistd.h>
#include <stdio.h>
#include <string.h>
char data_buf[16] = {0};
int main(int argc, char* argv[])
{   
    int fd = open("data.bin", O_WRONLY | O_CREAT, S_IRUSR | S_IWUSR);
    if (fd == -1) {
        printf("Cannot open file\n");
        return 1;
    }
    for(int i=0; i<16; i++) data_buf[i]=i+1;
    ssize_t bytes_written = write(fd, data_buf, 16);
    if (bytes_written == -1) {
        printf("Cannot write to file\n");
        close(fd);
        return 2;
    }
    close(fd);
    return 0;
}
$ gcc -Wall writefile.c -o w  /* 把上述源码编译成一个可执行文件w*/
$ ./w  /* 执行这个程序 */
$ ls -l
total 24
-rw------- 1 postgres postgres    16 Jan  6 16:28 data.bin /* 这是程序创建的文件 */
-rwxr-xr-x 1 postgres postgres 16136 Jan  6 16:28 w
-rw-r--r-- 1 postgres postgres   550 Jan  6 16:28 writefile.c
$ hexdump -C data.bin
00000000  01 02 03 04 05 06 07 08  09 0A 0B 0C 0D 0E 0F 10  |................|
00000010
$
```
上述源程序的逻辑很简单，就是打开一个文件data.bin，往里面写入16个字节。这是任何在Linux平台下写文件的基本套路，它使用了open()系统调用打开文件，使用write()系统调用往文件中写入数据，最后使用close()系统调用关闭这个文件。PostgreSQL也是使用这个模式往磁盘上写文件的。应用软件，操作系统和磁盘三者的关系可以可以用图3.22来表示。

![](x0285.svg) <!-- PostgreSQL的写磁盘操作 -->

当PostgreSQL通过write()系统调用把内存中的数据写入磁盘时，数据可能并没有真正的写入磁盘，而是保存在操作系统的I/O缓冲区内。操作系统认为合适的时机，再把数据真正地写入到磁盘中。操作系统的IO缓冲区也是内存，掉电后也会消失。如果数据依然在内存中，并没有真正写到磁盘上，此时服务器突然掉电，数据就丢失了。为了真正地把数据写入磁盘，Linux提供了fsync()和其它类似的函数来确保把内存中的数据刷到磁盘上。也就是说：write()成功了并不等于真正可靠，必须fsync()才能可靠地把数据写入到磁盘。为此，PostgreSQL提供了两个参数。第一个参数是fsync，它是一个布尔变量，取值范围为on或者off，表示是否打开或者关闭fsync功能。当然，如果fsync=off，会带来性能上的提升，但是带来的风险就是可能会发生数据丢失，所以在真正的生产系统中，fsync必须设置为on。在fsync为on的情况下，第二个参数wal_sync_method可以控制fsync的类型，它的取值范围包括open_datasync, fdatasync, fsync, fsync_writethrough, opne_sync几种可能性。这些取值和数据文件所在的文件系统相关，有的文件系统支持某一种或者某几种类型。为了测试不同类型的性能，PostgreSQL提供了一个简单使用的测试工具pg_test_fsync。它的使用方法非常简单，如下所示：

```
$ pg_test_fsync
5 seconds per test
O_DIRECT supported on this platform for open_datasync and open_sync.

Compare file sync methods using one 8kB write:
(in wal_sync_method preference order, except fdatasync is Linux's default)
        open_datasync                      4508.202 ops/sec     222 usecs/op
        fdatasync                          4275.360 ops/sec     234 usecs/op
        fsync                              3640.199 ops/sec     275 usecs/op
        fsync_writethrough                              n/a
        open_sync                          3772.740 ops/sec     265 usecs/op
......
Non-sync'ed 8kB writes:
        write                            448530.775 ops/sec       2 usecs/op
```
从上面的结果来看，如果fsync关闭，每次操作只要2微秒，在打开fsync的情况下，最快的open_datasync也需要222微秒。可见打开关闭fsync的性能差异很大，但是对于生产数据库，必须打开fsync，牺牲性能换取数据的可靠性。正式因为有了write和fsync在文件系统中的区别，所以PostgreSQL的很多系统视图也提供了磁盘读写的write和fsync不同的指标。


### 监控WAL记录和检查点

对于WAL记录的产生，PostgreSQL提供了一个系统视图pg_stat_wal。这个系统视图可以帮助我们了解WAL记录的产生情况。我们可以查看一下这个视图中的信息：
```
oracle=# select * from pg_stat_wal;
-[ RECORD 1 ]----+-----------------------------
wal_records      | 1284
wal_fpi          | 902
wal_bytes        | 4162675
wal_buffers_full | 1536
wal_write        | 1555
wal_sync         | 97
wal_write_time   | 0
wal_sync_time    | 0
stats_reset      | 2023-10-16 04:44:17.35114-06
```
关于这个系统视图的各列的含义，官方文档中有详细的说明。我们在这里把我们目前能够理解的指标的含义介绍一下。首先你可以注意最后一列，stats_reset。很多PostgreSQL的系统视图中的数据是累积性(cumulative)的，即这些数据是从某个时间点开始计算，随着时间的推移，数据的值是累积的，只增不减。stats_reset这一列就记录了其它列的数据是从什么时候开始累积的。第一列wal_records的值是1284，则表明从2023年10月16日开始，迄今为止，共计产生了1284条WAL记录。我们往往需要选取一个感兴趣的时间段，把开始和结束时刻采集的两个值进行相减，才能得到比较有意义的数据。譬如我们想知道一天之内产生了多少条WAL记录，就可以在某个时刻查询一下该系统视图，过了24个小时以后再查询一下，所获得的两个值相减，就是一天之内产生的数据。列wal_fpi是共计产生了多少条全页写类型的WAL记录。列wal_bytes是共计产生了多少字节的WAL记录。以上几列都是非常容易理解的。wal_write_time和wal_sync_time记录WAL数据写入磁盘所需要的时间。很显然，这两列的值如果很大，则表明磁盘速度有问题，或者某种因素阻碍了WAL记录的落盘。这两个值在数据库整体性能调优方面是需要关注的指标。为了获取这两个值，需要打开track_wal_io_timing参数，具体细节请查阅官方文档。

我们可以通过系统函数pg_stat_reset_shared()来重置这张系统表的统计信息，具体操作如下：
```
oracle=# select pg_stat_reset_shared('wal');
 pg_stat_reset_shared
----------------------

(1 row)
oracle=# select * from pg_stat_wal;
-[ RECORD 1 ]----+------------------------------
wal_records      | 0
wal_fpi          | 0
wal_bytes        | 0
wal_buffers_full | 0
wal_write        | 0
wal_sync         | 0
wal_write_time   | 0
wal_sync_time    | 0
stats_reset      | 2023-12-09 14:22:23.416003-07
```
我们可以看到，这张系统表的所有数据都被清零了，然后新的数据从2023年12月9日开始继续计数。另外一张有用的系统视图是pg_stat_bgwriter，它可以显示检查点的某些信息。我们来看一下它的具体定义：
```
postgres=# \d pg_stat_bgwriter
                        View "pg_catalog.pg_stat_bgwriter"
        Column         |           Type           | Collation | Nullable | Default
-----------------------+--------------------------+-----------+----------+---------
 checkpoints_timed     | bigint                   |           |          |
 checkpoints_req       | bigint                   |           |          |
 checkpoint_write_time | double precision         |           |          |
 checkpoint_sync_time  | double precision         |           |          |
 buffers_checkpoint    | bigint                   |           |          |
 buffers_clean         | bigint                   |           |          |
 maxwritten_clean      | bigint                   |           |          |
 buffers_backend       | bigint                   |           |          |
 buffers_backend_fsync | bigint                   |           |          |
 buffers_alloc         | bigint                   |           |          |
 stats_reset           | timestamp with time zone |           |          |
```
第一列checkpoints_timed的含义是已经执行的规划(scheduled)的检查点的次数。我们知道参数checkpoint_timeout规定了必须执行的检查点的时间间隔，超过了这个间隔必须执行一次检查点，这种检查点就是规划的检查点。第二列checkpoints_req表示被请求(requested)的检查点的执行次数。如果我们通过CHECKPOINT命令手工执行一次检查点，你就会发现这一列的值会增加一。因为手工执行的检查点并不是按照固定的节奏自动执行的，而是被请求的。在第四章讨论的数据库备份过程中，在备份开始时会执行一次检查点，这是另外一种类型的请求型检查点。 第三列checkpoint_write_time表示所有已经发生的检查点(包括第一列和第二列)操作总共花费的写磁盘的时间，单位是毫秒。我们用这个值除于第一列和第二列之和，就可以得到平均每次检查点的操作时间。第四列checkpoint_sync_time是所有已经发生的检查点操作花费在磁盘同步上的时间。这个时间过大，则表明磁盘的写速度比较慢。第五列buffers_checkpoint表示所有检查点操作写入的数据页的数量。

类似的我们可以使用pg_stat_reset_shared('bgwriter')函数来把这个系统视图中的数据重置清零。从名字上看，pg_stat_bgwriter是为后台进程bgwriter而设计的，为什么里面有检查点的信息呢？这是因为历史上bgwriter执行了检查点的工作，后来检查点的功能分化出来，设立了一个新的后台进程checkpointer，但是它的统计信息依然在bgwriter相关的系统视图中。在即将发布的PG 17中核心开发团队正在考虑为检查点设立一个单独的系统视图。


作为重要的基础性软件，数据库的可观测性也是一种重要的特性，PostgreSQL提供了越来越丰富的系统监控视图帮助用户深入理解数据库的运行状态。这些系统视图非常多，本书不打算给大家列一张大而全的清单，而是学习到哪块知识点，就见缝插针地介绍一下相关的系统视图。这种安排可以让读者不知不觉中就熟悉了常用的系统视图。

